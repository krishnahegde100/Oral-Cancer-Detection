{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 273\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import  img_to_array\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Image manipulations and arranging data\n",
    "import os\n",
    "from PIL import Image\n",
    "import theano\n",
    "theano.config.optimizer=\"None\"\n",
    "#Sklearn to modify the data\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "path=('/home/krishna/ML/ocd/resiz')  #path of resized images\n",
    "p1=('/home/krishna/ML/ocd/train_cancer')\n",
    "p2=('/home/krishna/ML/ocd/validation')\n",
    "imlist = os.listdir(path)\n",
    "#print(imlist)\n",
    "im1 = array(Image.open(path+'//'+ imlist[0]))\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# In[13]:\n",
    "\n",
    "train_data_dir = p1\n",
    "validation_data_dir = p2\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "img_width=400\n",
    "img_height=400\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krishna/ML/ocd/train_cancer\n",
      "['no_cancer', 'cancer']\n"
     ]
    }
   ],
   "source": [
    "# In[11]:\n",
    "\n",
    "m=150\n",
    "n=150\n",
    "print(p1)\n",
    "classes=os.listdir(p1)\n",
    "print(classes)\n",
    "x=[]\n",
    "y=[]\n",
    "for fol in classes:\n",
    "    #print(fol)\n",
    "    imgfiles=os.listdir(p1+'//'+fol);\n",
    "    for img in imgfiles:\n",
    "        im=Image.open(p1+'//'+fol+'//'+img);\n",
    "        im=im.convert(mode='RGB')\n",
    "        imrs=im.resize((m,n))\n",
    "        imrs=img_to_array(imrs)/255;\n",
    "        imrs=imrs.transpose(2,0,1);\n",
    "        imrs=imrs.reshape(3,m,n);\n",
    "        x.append(imrs)\n",
    "        y.append(fol)\n",
    "#print(x) \n",
    "x=np.array(x);\n",
    "y=np.array(y);\n",
    "#print(classes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 150, 150)\n",
      "['cancer' 'no_cancer' 'cancer' 'cancer' 'cancer' 'cancer' 'no_cancer'\n",
      " 'no_cancer' 'cancer' 'cancer' 'no_cancer' 'no_cancer' 'no_cancer'\n",
      " 'no_cancer' 'cancer' 'no_cancer' 'no_cancer' 'cancer' 'cancer'\n",
      " 'no_cancer' 'cancer' 'cancer' 'no_cancer' 'cancer' 'cancer' 'cancer'\n",
      " 'no_cancer' 'no_cancer' 'no_cancer' 'cancer' 'no_cancer' 'cancer'\n",
      " 'no_cancer' 'no_cancer' 'cancer' 'no_cancer' 'cancer' 'cancer'\n",
      " 'no_cancer' 'cancer' 'no_cancer' 'cancer' 'cancer' 'cancer' 'no_cancer'\n",
      " 'cancer' 'cancer' 'no_cancer' 'cancer' 'cancer' 'cancer' 'cancer'\n",
      " 'cancer' 'cancer' 'no_cancer' 'cancer' 'no_cancer' 'no_cancer'\n",
      " 'no_cancer' 'cancer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(3, 150, 1..., padding=\"same\")`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5))`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5))`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159 samples, validate on 40 samples\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 40s 254ms/step - loss: 6.9826 - acc: 0.5503 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 43s 273ms/step - loss: 7.0064 - acc: 0.5629 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 44s 276ms/step - loss: 7.0067 - acc: 0.5629 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 44s 275ms/step - loss: 7.0568 - acc: 0.5597 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 44s 275ms/step - loss: 7.0573 - acc: 0.5597 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 44s 276ms/step - loss: 7.0562 - acc: 0.5597 - val_loss: 9.2174 - val_acc: 0.4250\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 44s 275ms/step - loss: 6.0839 - acc: 0.5660 - val_loss: 1.4426 - val_acc: 0.4250\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 44s 275ms/step - loss: 0.8231 - acc: 0.5629 - val_loss: 0.6971 - val_acc: 0.4250\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 44s 276ms/step - loss: 0.7211 - acc: 0.5409 - val_loss: 0.7229 - val_acc: 0.4250\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 44s 275ms/step - loss: 0.7437 - acc: 0.5314 - val_loss: 0.7016 - val_acc: 0.4250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f410ab98208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[12]:\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.3,random_state=None)\n",
    "print(x_train.shape[1:])\n",
    "print(y_test)\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "batch_size=6\n",
    "nb_classes=len(classes)\n",
    "nb_epoch=10\n",
    "nb_pool=2\n",
    "nb_conv=5\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=None)\n",
    "\n",
    "uniques, id_train=np.unique(y_train,return_inverse=True)\n",
    "Y_train=np_utils.to_categorical(id_train,nb_classes)\n",
    "uniques, id_test=np.unique(y_test,return_inverse=True)\n",
    "Y_test=np_utils.to_categorical(id_test,nb_classes)\n",
    "\n",
    "model= Sequential()\n",
    "nb_filters=32\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv,border_mode='same',input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "nb_filters=64\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv));\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)));\n",
    "nb_filters=128\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv));\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)));\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(186));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(nb_classes));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "model.fit(x_train,Y_train,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(x_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# In[46]:\n",
    "\n",
    "#saving model in json\n",
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_cancer', 'cancer']\n",
      "no_cancer --> 0.52774936\n",
      "cancer --> 0.46369448\n",
      "{'no_cancer': 0.52774936, 'cancer': 0.46369448}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4y5JDfo/MzDqpYdv3GAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f410a71f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# In[15]:\n",
    "import matplotlib.pyplot as plt\n",
    "m=150\n",
    "n=150\n",
    "classes=os.listdir(p1)\n",
    "im = Image.open('/home/krishna/ML/ocd/test_cancer/test.jpeg');\n",
    "imrs = im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255;\n",
    "imrs=imrs.transpose(2,0,1);\n",
    "imrs=imrs.reshape(3,m,n);\n",
    "print(classes)\n",
    "#print(imrs)\n",
    "x=[]\n",
    "x.append(imrs)\n",
    "x=np.array(x);\n",
    "predictions = loaded_model.predict(x)\n",
    "#print(predictions)\n",
    "out={}\n",
    "for i in range(2):\n",
    "    print(\"%s --> %s\"%(classes[i],predictions[0][i]))\n",
    "    out[classes[i]]=(predictions[0][i])\n",
    "#print(out)\n",
    "import operator\n",
    "sorted_x =out\n",
    "z=sorted(out.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(out)\n",
    "plt.bar(range(len(sorted_x)), list(sorted_x.values()), align='center')\n",
    "plt.xticks(range(len(sorted_x)), list(sorted_x.keys()))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "im=Image.open('/home/krishna/ML/ocd/test/test.jpg');\n",
    "im=im.convert(mode='RGB')\n",
    "imrs=im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255;\n",
    "#print(imrs)\n",
    "imrs=imrs.transpose(2,0,1);\n",
    "imrs=imrs.reshape(3,m,n);\n",
    "#print(imrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
