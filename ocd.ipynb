{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import  img_to_array\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Image manipulations and arranging data\n",
    "import os\n",
    "from PIL import Image\n",
    "import theano\n",
    "theano.config.optimizer=\"None\"\n",
    "#Sklearn to modify the data\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input image dimensions\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "path=('/home/krishna/ML/ocd/resiz')  #path of resized images\n",
    "p1=('/home/krishna/ML/ocd/train')\n",
    "p2=('/home/krishna/ML/ocd/validation')\n",
    "imlist = os.listdir(path)\n",
    "#print(imlist)\n",
    "im1 = array(Image.open(path+'//'+ imlist[0]))\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "print(m,n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1518 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[13]:\n",
    "\n",
    "train_data_dir = p1\n",
    "validation_data_dir = p2\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "img_width=400\n",
    "img_height=400\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krishna/ML/ocd/train\n",
      "['rose', 'sunflower']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[11]:\n",
    "\n",
    "m=150\n",
    "n=150\n",
    "print(p1)\n",
    "classes=os.listdir(p1)\n",
    "print(classes)\n",
    "x=[]\n",
    "y=[]\n",
    "for fol in classes:\n",
    "    #print(fol)\n",
    "    imgfiles=os.listdir(p1+'//'+fol);\n",
    "    for img in imgfiles:\n",
    "        im=Image.open(p1+'//'+fol+'//'+img);\n",
    "        im=im.convert(mode='RGB')\n",
    "        imrs=im.resize((m,n))\n",
    "        imrs=img_to_array(imrs)/255;\n",
    "        imrs=imrs.transpose(2,0,1);\n",
    "        imrs=imrs.reshape(3,m,n);\n",
    "        x.append(imrs)\n",
    "        y.append(fol)\n",
    "#print(x) \n",
    "x=np.array(x);\n",
    "y=np.array(y);\n",
    "#print(classes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 150, 150)\n",
      "['rose' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower'\n",
      " 'rose' 'sunflower' 'rose' 'rose' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'rose'\n",
      " 'rose' 'sunflower' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'rose' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'rose' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower' 'rose'\n",
      " 'rose' 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'rose' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower' 'rose'\n",
      " 'sunflower' 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'rose' 'rose' 'sunflower' 'rose' 'rose' 'rose' 'sunflower' 'rose' 'rose'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'rose' 'rose' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'sunflower'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'sunflower' 'sunflower'\n",
      " 'rose' 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'sunflower'\n",
      " 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower'\n",
      " 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'rose'\n",
      " 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose' 'sunflower'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower' 'rose'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'sunflower' 'rose'\n",
      " 'rose' 'rose' 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower'\n",
      " 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'sunflower'\n",
      " 'rose' 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'rose' 'rose' 'rose' 'rose'\n",
      " 'rose' 'rose' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose'\n",
      " 'rose' 'sunflower' 'rose' 'rose' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'rose' 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'rose' 'rose'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'rose' 'rose' 'rose' 'rose' 'sunflower' 'rose'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'rose' 'sunflower' 'sunflower' 'rose' 'rose'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'rose' 'rose' 'rose' 'rose'\n",
      " 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'sunflower' 'rose' 'sunflower' 'rose' 'sunflower'\n",
      " 'rose' 'sunflower' 'rose' 'sunflower' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'sunflower' 'rose' 'rose' 'rose' 'sunflower' 'sunflower'\n",
      " 'sunflower' 'rose' 'rose' 'sunflower' 'sunflower' 'rose' 'sunflower'\n",
      " 'sunflower' 'rose' 'sunflower' 'sunflower' 'sunflower' 'rose' 'rose']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[12]:\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.3,random_state=None)\n",
    "print(x_train.shape[1:])\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(3, 150, 1..., padding=\"same\")`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5))`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5))`\n",
      "/home/krishna/anaconda3/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1214 samples, validate on 304 samples\n",
      "Epoch 1/5\n",
      "1214/1214 [==============================] - 337s 278ms/step - loss: 0.6898 - acc: 0.6606 - val_loss: 0.5824 - val_acc: 0.7039\n",
      "Epoch 2/5\n",
      "1214/1214 [==============================] - 339s 279ms/step - loss: 0.4362 - acc: 0.8377 - val_loss: 0.3860 - val_acc: 0.8339\n",
      "Epoch 3/5\n",
      "1214/1214 [==============================] - 338s 278ms/step - loss: 0.3779 - acc: 0.8661 - val_loss: 0.2744 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "1214/1214 [==============================] - 339s 279ms/step - loss: 0.3304 - acc: 0.8740 - val_loss: 0.2816 - val_acc: 0.8602\n",
      "Epoch 5/5\n",
      "1214/1214 [==============================] - 335s 276ms/step - loss: 0.3531 - acc: 0.8863 - val_loss: 0.2557 - val_acc: 0.8766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2017a26780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[29]:\n",
    "\n",
    "batch_size=16\n",
    "nb_classes=len(classes)\n",
    "nb_epoch=5\n",
    "nb_pool=2\n",
    "nb_conv=5\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=None)\n",
    "\n",
    "uniques, id_train=np.unique(y_train,return_inverse=True)\n",
    "Y_train=np_utils.to_categorical(id_train,nb_classes)\n",
    "uniques, id_test=np.unique(y_test,return_inverse=True)\n",
    "Y_test=np_utils.to_categorical(id_test,nb_classes)\n",
    "\n",
    "model= Sequential()\n",
    "nb_filters=32\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv,border_mode='same',input_shape=x_train.shape[1:]))\n",
    "\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "nb_filters=64\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv));\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)));\n",
    "nb_filters=128\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv));\n",
    "model.add(Activation('relu'));\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)));\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(186));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(nb_classes));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "\n",
    "model.fit(x_train,Y_train,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(x_test, Y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[46]:\n",
    "\n",
    "#saving model in json\n",
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[4]:\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rose', 'sunflower']\n",
      "rose --> 0.9570614\n",
      "sunflower --> 0.042047665\n",
      "{'rose': 0.9570614, 'sunflower': 0.042047665}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20176234a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[15]:\n",
    "import matplotlib.pyplot as plt\n",
    "m=150\n",
    "n=150\n",
    "classes=os.listdir(p1)\n",
    "im = Image.open('/home/krishna/ML/ocd/test/test.jpg');\n",
    "imrs = im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255;\n",
    "imrs=imrs.transpose(2,0,1);\n",
    "imrs=imrs.reshape(3,m,n);\n",
    "print(classes)\n",
    "#print(imrs)\n",
    "x=[]\n",
    "x.append(imrs)\n",
    "x=np.array(x);\n",
    "predictions = loaded_model.predict(x)\n",
    "#print(predictions)\n",
    "out={}\n",
    "for i in range(2):\n",
    "    print(\"%s --> %s\"%(classes[i],predictions[0][i]))\n",
    "    out[classes[i]]=(predictions[0][i])\n",
    "#print(out)\n",
    "import operator\n",
    "sorted_x =out\n",
    "z=sorted(out.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(out)\n",
    "plt.bar(range(len(sorted_x)), list(sorted_x.values()), align='center')\n",
    "plt.xticks(range(len(sorted_x)), list(sorted_x.keys()))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "im=Image.open('/home/krishna/ML/ocd/test/test.jpg');\n",
    "im=im.convert(mode='RGB')\n",
    "imrs=im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255;\n",
    "#print(imrs)\n",
    "imrs=imrs.transpose(2,0,1);\n",
    "imrs=imrs.reshape(3,m,n);\n",
    "#print(imrs)\n",
    "\n",
    "\n",
    "# In[52]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/modules/imgproc/src/imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aecc0f073b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m          \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mgdata/frame%d.jpg'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m          \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m          \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m          \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgdata/frame%d.jpg'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m          \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/modules/imgproc/src/imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "m=150\n",
    "n=150\n",
    "import os,cv2\n",
    "import operator\n",
    "vidcap = cv2.VideoCapture('../Videos/test.mp4');\n",
    "\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "i=0\n",
    "r=0\n",
    "try:\n",
    "    if not os.path.exists('mgdata'):\n",
    "        os.mkdir('mgdata')\n",
    "except OSError:\n",
    "    print('already exists')\n",
    "while success:\n",
    "    success,image = vidcap.read()\n",
    "    #print('read a new frame:',success)\n",
    "    if count%10 == 0 :\n",
    "         i+=1\n",
    "         cv2.imwrite('mgdata/frame%d.jpg'%i,image)\n",
    "         img=cv2.imread('mgdata/frame%d.jpg'%i)\n",
    "         dim = (60, 60)\n",
    "         res = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "         cv2.imwrite('imgdata/frame%d.jpg'%i,res)\n",
    "         print(res.shape)\n",
    "         cv2.waitKey(0)\n",
    "         im = Image.open('mgdata/frame%d.jpg'%i);\n",
    "         imrs = im.resize((m,n))\n",
    "         imrs=img_to_array(imrs)/255;\n",
    "         imrs=imrs.transpose(2,0,1);\n",
    "         imrs=imrs.reshape(3,m,n);\n",
    "#print(classes)\n",
    "         x=[]\n",
    "         x.append(imrs)\n",
    "         x=np.array(x);\n",
    "         predictions = loaded_model.predict(x)\n",
    "         out={}\n",
    "         for k in range(2):\n",
    "             print(\"%s --> %s\"%(classes[k],predictions[0][k]))\n",
    "             out[classes[k]]=(predictions[0][k])\n",
    "         \n",
    "         sorted_x =out\n",
    "         z=sorted(out.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "         plt.bar(range(len(sorted_x)), list(sorted_x.values()), align='center')\n",
    "         plt.xticks(range(len(sorted_x)), list(sorted_x.keys()))\n",
    "         plt.show()\n",
    "\n",
    "         \n",
    "    count+=1\n",
    "print(i)\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
